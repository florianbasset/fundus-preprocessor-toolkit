{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The file exists\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/clahe.cpp:353: error: (-215:Assertion failed) _src.type() == CV_8UC1 || _src.type() == CV_16UC1 in function 'apply'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m image \u001b[38;5;241m=\u001b[39m read_image(image_path)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Prétraitement\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m preprocessed_image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessing_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(preprocessed_image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     22\u001b[0m preprocessed_image \u001b[38;5;241m=\u001b[39m (preprocessed_image \u001b[38;5;241m-\u001b[39m preprocessed_image\u001b[38;5;241m.\u001b[39mmin((\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m),keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\u001b[38;5;241m/\u001b[39m(preprocessed_image\u001b[38;5;241m.\u001b[39mmax((\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m), keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m-\u001b[39mpreprocessed_image\u001b[38;5;241m.\u001b[39mmin((\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m),keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/Documents/fundus_preprocess_toolkit/src/fundus_prepro/script/core.py:7\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image, color_space, method)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image, color_space, method):\n\u001b[1;32m      6\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m Preprocessor(image)\n\u001b[0;32m----> 7\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m~/Documents/fundus_preprocess_toolkit/src/fundus_prepro/script/preprocessor.py:111\u001b[0m, in \u001b[0;36mPreprocessor.apply_preprocessing\u001b[0;34m(self, color_space, method)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_preprocessing\u001b[39m(\u001b[38;5;28mself\u001b[39m, color_space, method):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_space\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fundus_preprocess_toolkit/src/fundus_prepro/script/preprocessor.py:45\u001b[0m, in \u001b[0;36mPreprocessor.apply_operation\u001b[0;34m(self, image, operation, color_space)\u001b[0m\n\u001b[1;32m     43\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenoising(a)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSarki\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_sarki\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBilateral\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     47\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_bilateral_filter(image)\n",
      "File \u001b[0;32m~/Documents/fundus_preprocess_toolkit/src/fundus_prepro/script/preprocessor.py:135\u001b[0m, in \u001b[0;36mPreprocessor.apply_sarki\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_sarki\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 135\u001b[0m     image_enhancement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_sarki_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_enhancement\n",
      "File \u001b[0;32m~/Documents/fundus_preprocess_toolkit/src/fundus_prepro/script/preprocessor.py:142\u001b[0m, in \u001b[0;36mPreprocessor.apply_sarki_preprocess\u001b[0;34m(self, image, mu0)\u001b[0m\n\u001b[1;32m    140\u001b[0m h, s, v \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39msplit(hsv_image)\n\u001b[1;32m    141\u001b[0m clahe \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcreateCLAHE(clipLimit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m, tileGridSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m--> 142\u001b[0m v_clahe \u001b[38;5;241m=\u001b[39m \u001b[43mclahe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m navg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(v_clahe)\n\u001b[1;32m    144\u001b[0m nCLIP \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/clahe.cpp:353: error: (-215:Assertion failed) _src.type() == CV_8UC1 || _src.type() == CV_16UC1 in function 'apply'\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fundus_prepro.script.core import preprocess_image\n",
    "from fundus_prepro.utils.io import read_image, save_image\n",
    "from fundus_prepro.utils.plot import plot_image\n",
    "import numpy as np\n",
    "\n",
    "image_path = '/home/florian/Downloads/image.jpeg'  \n",
    "output_path = '/home/florian/Documents/output_image.png'  \n",
    "origin_path = '/home/florian/Documents/origin_image.png'  \n",
    "color_space = 'RGB'  # Peut être 'LAB' ou 'HSV' ou RGB\n",
    "preprocessing_method = 'Seoud'  \n",
    "# Peut être 'CLAHE', 'Bilateral', 'Tophat', 'Gaussian', 'IntensityNorm', Blackhat\n",
    "# combinaison5, combinaison4, combinaison3, combinaison2, combinaison1\n",
    "\n",
    "# Lecture \n",
    "image = read_image(image_path)\n",
    "\n",
    "# Prétraitement\n",
    "preprocessed_image = preprocess_image(image_path, color_space, preprocessing_method)\n",
    "print(preprocessed_image.shape)\n",
    "preprocessed_image = (preprocessed_image - preprocessed_image.min((0,1),keepdims=True))/(preprocessed_image.max((0,1), keepdims=True)-preprocessed_image.min((0,1),keepdims=True))\n",
    "print(preprocessed_image.min())\n",
    "print(preprocessed_image.max())\n",
    "# Enregistrement\n",
    "save_image(preprocessed_image, output_path)\n",
    "\n",
    "# Affichage\n",
    "plot_image(image) \n",
    "preprocessed_image = preprocessed_image.astype(np.float32)\n",
    "plot_image(preprocessed_image, title=f'Preprocessed Image ({color_space} - {preprocessing_method})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
